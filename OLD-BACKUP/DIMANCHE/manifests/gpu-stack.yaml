# =============================================================================
# NVIDIA GPU Stack for Talos Kubernetes (CDI Mode)
# =============================================================================
#
# This manifest is for manual deployment after cluster bootstrap.
# It's already included in the cloud-init, so you only need this if:
# - You want to redeploy the GPU stack
# - You're upgrading components
# - You're troubleshooting
#
# Usage:
#   kubectl apply -f gpu-stack.yaml
#
# MIG Configuration:
#   kubectl -n nvidia-gpu-stack edit configmap mig-config
#   kubectl -n nvidia-gpu-stack rollout restart daemonset/nvidia-device-plugin
#
# =============================================================================

---
apiVersion: v1
kind: Namespace
metadata:
  name: nvidia-gpu-stack
  labels:
    app.kubernetes.io/name: nvidia-gpu-stack
    pod-security.kubernetes.io/enforce: privileged
    pod-security.kubernetes.io/audit: privileged
    pod-security.kubernetes.io/warn: privileged

---
# RuntimeClass for GPU workloads
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
  labels:
    app.kubernetes.io/name: nvidia-gpu-stack
handler: nvidia

---
# =============================================================================
# MIG Configuration
# =============================================================================
# Profile IDs for H100 80GB:
#   0  = 7g.80gb (80GB, full GPU in MIG mode)
#   5  = 4g.40gb (40GB)
#   9  = 3g.40gb (40GB)
#   14 = 2g.20gb (20GB)
#   19 = 1g.10gb (10GB)
#
# Example configurations:
#   7x 1g.10gb: "19,19,19,19,19,19,19"
#   3x 2g.20gb: "14,14,14"
#   2x 3g.40gb: "9,9"
#   Mixed:      "5,9" (1x 4g.40gb + 1x 3g.40gb)
# =============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: mig-config
  namespace: nvidia-gpu-stack
  labels:
    app.kubernetes.io/name: nvidia-gpu-stack
data:
  MIG_ENABLED: "true"
  MIG_PROFILE: "all-1g.10gb"
  MIG_PROFILE_CONFIG: "19,19,19,19,19,19,19"
  MIG_INSTANCE_COUNT: "7"

---
# =============================================================================
# Node Feature Discovery (NFD)
# =============================================================================

apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: nodefeatures.nfd.k8s-sigs.io
spec:
  group: nfd.k8s-sigs.io
  names:
    kind: NodeFeature
    listKind: NodeFeatureList
    plural: nodefeatures
    singular: nodefeature
  scope: Namespaced
  versions:
    - name: v1alpha1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              x-kubernetes-preserve-unknown-fields: true

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfd-master
  namespace: nvidia-gpu-stack

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfd-worker
  namespace: nvidia-gpu-stack

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nfd-master
rules:
  - apiGroups: [""]
    resources: ["nodes", "nodes/status"]
    verbs: ["get", "list", "watch", "patch", "update"]
  - apiGroups: ["nfd.k8s-sigs.io"]
    resources: ["nodefeatures"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["create", "get", "update"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nfd-master
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nfd-master
subjects:
  - kind: ServiceAccount
    name: nfd-master
    namespace: nvidia-gpu-stack

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nfd-worker
rules:
  - apiGroups: ["nfd.k8s-sigs.io"]
    resources: ["nodefeatures"]
    verbs: ["create", "get", "update"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nfd-worker
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nfd-worker
subjects:
  - kind: ServiceAccount
    name: nfd-worker
    namespace: nvidia-gpu-stack

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfd-master
  namespace: nvidia-gpu-stack
  labels:
    app.kubernetes.io/name: nvidia-gpu-stack
    app.kubernetes.io/component: nfd-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nfd-master
  template:
    metadata:
      labels:
        app: nfd-master
    spec:
      serviceAccountName: nfd-master
      tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists
          effect: NoSchedule
      containers:
        - name: nfd-master
          image: registry.k8s.io/nfd/node-feature-discovery:v0.16.6
          imagePullPolicy: IfNotPresent
          command: ["nfd-master"]
          args: ["-port=8080"]
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          ports:
            - containerPort: 8080
              name: grpc
          resources:
            requests:
              cpu: 10m
              memory: 32Mi
            limits:
              cpu: 100m
              memory: 128Mi

---
apiVersion: v1
kind: Service
metadata:
  name: nfd-master
  namespace: nvidia-gpu-stack
spec:
  selector:
    app: nfd-master
  ports:
    - port: 8080
      name: grpc

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nfd-worker
  namespace: nvidia-gpu-stack
  labels:
    app.kubernetes.io/name: nvidia-gpu-stack
    app.kubernetes.io/component: nfd-worker
spec:
  selector:
    matchLabels:
      app: nfd-worker
  template:
    metadata:
      labels:
        app: nfd-worker
    spec:
      serviceAccountName: nfd-worker
      dnsPolicy: ClusterFirstWithHostNet
      tolerations:
        - operator: Exists
      containers:
        - name: nfd-worker
          image: registry.k8s.io/nfd/node-feature-discovery:v0.16.6
          imagePullPolicy: IfNotPresent
          command: ["nfd-worker"]
          args: ["-server=nfd-master.nvidia-gpu-stack.svc.cluster.local:8080"]
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: host-boot
              mountPath: /host-boot
              readOnly: true
            - name: host-sys
              mountPath: /host-sys
              readOnly: true
          resources:
            requests:
              cpu: 10m
              memory: 32Mi
            limits:
              cpu: 100m
              memory: 128Mi
      volumes:
        - name: host-boot
          hostPath:
            path: /boot
        - name: host-sys
          hostPath:
            path: /sys

---
# =============================================================================
# GPU Labeler
# =============================================================================

apiVersion: v1
kind: ServiceAccount
metadata:
  name: gpu-operator
  namespace: nvidia-gpu-stack

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: gpu-operator
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch", "patch", "update"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: gpu-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: gpu-operator
subjects:
  - kind: ServiceAccount
    name: gpu-operator
    namespace: nvidia-gpu-stack

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-labeler
  namespace: nvidia-gpu-stack
  labels:
    app.kubernetes.io/name: nvidia-gpu-stack
    app.kubernetes.io/component: gpu-labeler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gpu-labeler
  template:
    metadata:
      labels:
        app: gpu-labeler
    spec:
      serviceAccountName: gpu-operator
      tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists
          effect: NoSchedule
      containers:
        - name: labeler
          image: bitnami/kubectl:latest
          imagePullPolicy: IfNotPresent
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "GPU Labeler started"
              while true; do
                # Label nodes with NVIDIA GPU (PCI vendor 10de)
                for node in $(kubectl get nodes -l feature.node.kubernetes.io/pci-10de.present=true -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
                  CURRENT=$(kubectl get node $node -o jsonpath='{.metadata.labels.nvidia\.com/gpu\.present}' 2>/dev/null)
                  if [ "$CURRENT" != "true" ]; then
                    echo "[$(date '+%H:%M:%S')] Labeling $node"
                    kubectl label node $node nvidia.com/gpu.present=true --overwrite
                  fi
                done
                
                # Cleanup: remove label from nodes without GPU
                for node in $(kubectl get nodes -l nvidia.com/gpu.present=true -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
                  HAS_GPU=$(kubectl get node $node -o jsonpath='{.metadata.labels.feature\.node\.kubernetes\.io/pci-10de\.present}' 2>/dev/null)
                  if [ "$HAS_GPU" != "true" ]; then
                    echo "[$(date '+%H:%M:%S')] Removing GPU label from $node"
                    kubectl label node $node nvidia.com/gpu.present- 2>/dev/null || true
                  fi
                done
                
                sleep 30
              done
          resources:
            requests:
              cpu: 10m
              memory: 32Mi
            limits:
              cpu: 50m
              memory: 64Mi

---
# =============================================================================
# NVIDIA Device Plugin (CDI Mode)
# =============================================================================

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin
  namespace: nvidia-gpu-stack
  labels:
    app.kubernetes.io/name: nvidia-gpu-stack
    app.kubernetes.io/component: device-plugin
spec:
  selector:
    matchLabels:
      app: nvidia-device-plugin
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: nvidia-device-plugin
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
        - key: node.kubernetes.io/not-ready
          operator: Exists
          effect: NoSchedule
      priorityClassName: system-node-critical
      containers:
        - name: nvidia-device-plugin
          image: nvcr.io/nvidia/k8s-device-plugin:v0.17.0
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
          env:
            # CDI Mode (recommended for Talos)
            - name: DEVICE_LIST_STRATEGY
              value: "cdi-annotations"
            - name: CDI_ANNOTATION_PREFIX
              value: "cdi.k8s.io/"
            - name: NVIDIA_CTK_PATH
              value: "/usr/local/bin/nvidia-ctk"
            # General settings
            - name: FAIL_ON_INIT_ERROR
              value: "false"
            - name: MIG_STRATEGY
              value: "single"
            - name: PASS_DEVICE_SPECS
              value: "true"
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: "all"
          volumeMounts:
            - name: device-plugin
              mountPath: /var/lib/kubelet/device-plugins
            - name: cdi
              mountPath: /var/run/cdi
          resources:
            requests:
              cpu: 10m
              memory: 32Mi
            limits:
              cpu: 100m
              memory: 128Mi
      volumes:
        - name: device-plugin
          hostPath:
            path: /var/lib/kubelet/device-plugins
        - name: cdi
          hostPath:
            path: /var/run/cdi
            type: DirectoryOrCreate

---
# =============================================================================
# MIG Configurator (Optional - runs once per node)
# =============================================================================
# This DaemonSet configures MIG instances on GPU nodes.
# It runs as an init container and then just sleeps.
# To reconfigure MIG:
#   1. Delete MIG instances: nvidia-smi mig -dci && nvidia-smi mig -dgi
#   2. Update mig-config ConfigMap
#   3. Restart: kubectl -n nvidia-gpu-stack rollout restart daemonset/mig-configurator
# =============================================================================

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: mig-configurator
  namespace: nvidia-gpu-stack
  labels:
    app.kubernetes.io/name: nvidia-gpu-stack
    app.kubernetes.io/component: mig-configurator
spec:
  selector:
    matchLabels:
      app: mig-configurator
  template:
    metadata:
      labels:
        app: mig-configurator
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      priorityClassName: system-node-critical
      
      initContainers:
        - name: configure-mig
          image: nvcr.io/nvidia/cuda:12.2.0-base-ubuntu22.04
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
          env:
            - name: MIG_ENABLED
              valueFrom:
                configMapKeyRef:
                  name: mig-config
                  key: MIG_ENABLED
            - name: MIG_PROFILE_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: mig-config
                  key: MIG_PROFILE_CONFIG
            - name: MIG_INSTANCE_COUNT
              valueFrom:
                configMapKeyRef:
                  name: mig-config
                  key: MIG_INSTANCE_COUNT
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "=== MIG Configurator ==="
              echo "Node: $NODE_NAME"
              echo "MIG Enabled: $MIG_ENABLED"
              echo "Profile Config: $MIG_PROFILE_CONFIG"
              
              if [ "$MIG_ENABLED" != "true" ]; then
                echo "MIG disabled, skipping"
                exit 0
              fi
              
              if ! nvidia-smi &>/dev/null; then
                echo "NVIDIA drivers not ready"
                exit 0
              fi
              
              nvidia-smi -L
              
              MIG_MODE=$(nvidia-smi -i 0 --query-gpu=mig.mode.current --format=csv,noheader 2>/dev/null || echo "N/A")
              echo "Current MIG mode: $MIG_MODE"
              
              if [ "$MIG_MODE" != "Enabled" ]; then
                echo "MIG mode not enabled. Enable with: nvidia-smi -mig 1 (requires reboot)"
                exit 0
              fi
              
              EXISTING=$(nvidia-smi mig -lgi 2>/dev/null | grep -c "MIG" || echo 0)
              echo "Existing MIG instances: $EXISTING"
              
              if [ "$EXISTING" -ge "$MIG_INSTANCE_COUNT" ]; then
                echo "MIG already configured"
                nvidia-smi mig -lgi
                exit 0
              fi
              
              echo "Creating MIG instances: $MIG_PROFILE_CONFIG"
              nvidia-smi mig -cgi $MIG_PROFILE_CONFIG -C || true
              nvidia-smi mig -lgi
              echo "MIG configuration complete"
          resources:
            limits:
              # SUPPRIMEZ OU COMMENTEZ LA LIGNE CI-DESSOUS
              # nvidia.com/gpu: 1 
              cpu: 100m
              memory: 128Mi
      
      containers:
        - name: pause
          image: registry.k8s.io/pause:3.9
          resources:
            requests:
              cpu: 5m
              memory: 16Mi
            limits:
              cpu: 10m
              memory: 32Mi
